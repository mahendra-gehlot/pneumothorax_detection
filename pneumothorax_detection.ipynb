{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# import os, sys, subprocess\n",
        "# if \"google.colab\" in sys.modules:\n",
        "#     cmd = \"pip install --upgrade watermark blackcellmagic\"\n",
        "#     process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
        "\n",
        "# %load_ext blackcellmagic"
      ],
      "metadata": {
        "id": "KpqQqpv6PG__"
      },
      "id": "KpqQqpv6PG__",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c085d928",
      "metadata": {
        "id": "c085d928"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ot48Em6A5jz",
        "outputId": "5a63a52a-db69-4582-9208-5c42517389b9"
      },
      "id": "9Ot48Em6A5jz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting base path\n",
        "PATH = os.getcwd() + '/gdrive/MyDrive/AIMIA/'"
      ],
      "metadata": {
        "id": "GkbsYCtQBOsw"
      },
      "id": "GkbsYCtQBOsw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logger preparation\n",
        "import logging\n",
        "\n",
        "files_list= os.listdir(PATH)\n",
        "logging.basicConfig(filename='myfirstlog.log', level=logging.INFO)"
      ],
      "metadata": {
        "id": "6y33QPkEWYb9"
      },
      "id": "6y33QPkEWYb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install validators"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjumCrpXGzqc",
        "outputId": "a47601c6-1f65-4906-adf7-d3cdafc20931"
      },
      "id": "FjumCrpXGzqc",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting validators\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators) (4.4.2)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=64204b4a5f31a2802386b4061b16325f17bb7061ee9ed1df377eee6aa48c2ee2\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n",
            "Successfully built validators\n",
            "Installing collected packages: validators\n",
            "Successfully installed validators-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f55c10cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f55c10cf",
        "outputId": "3c1dd16e-0304-480d-c85a-c629a2ce499e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  \"You are about to download and run code from an untrusted repository. In a future release, this won't \"\n",
            "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /root/.cache/torch/hub/torchhub.zip\n",
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:14: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  \"pytorch_quantization module not found, quantization will not be available\"\n",
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:18: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  \"pytorch_quantization module not found, quantization will not be available\"\n"
          ]
        }
      ],
      "source": [
        "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "39acacea",
      "metadata": {
        "id": "39acacea"
      },
      "outputs": [],
      "source": [
        "# train_data_m contain all the images name and ids\n",
        "all_data = pd.read_csv(PATH + 'train_data_m.csv')\n",
        "\n",
        "image_ids = all_data['file_name'].to_numpy()\n",
        "labels = all_data['target'].to_numpy()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_ids, labels, test_size= 0.20, random_state=42)\n",
        "\n",
        "# creating dataset for train_validation\n",
        "train_df = pd.concat([pd.Series(X_train),pd.Series(y_train)],axis = 1)\n",
        "train_df.to_csv(PATH +'train_data.csv',index = False)\n",
        "\n",
        "# creating dataset for testing \n",
        "test_df = pd.concat([pd.Series(X_test),pd.Series(y_test)],axis = 1)\n",
        "test_df.to_csv(PATH + 'test_data.csv',index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "7d02491e",
      "metadata": {
        "id": "7d02491e"
      },
      "outputs": [],
      "source": [
        "class PneumothoraxImgDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, annotations_file, img_dir, dim = 256):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform= transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((dim,dim)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "1f23e11e",
      "metadata": {
        "id": "1f23e11e"
      },
      "outputs": [],
      "source": [
        "Test_Dataset = PneumothoraxImgDataset(PATH + 'test_data.csv',PATH + 'small_train_data_set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "df7f8f3c",
      "metadata": {
        "id": "df7f8f3c"
      },
      "outputs": [],
      "source": [
        "class TV_Dataset(Dataset):\n",
        "    def __init__(self, file_names, labels, img_dir,dim = 256):\n",
        "        self.img_name =file_names\n",
        "        self.labels = labels\n",
        "        self.img_dir = img_dir\n",
        "        self.transform= transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((dim,dim)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_name)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_name[idx])\n",
        "        image = read_image(img_path)\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e21eb61b",
      "metadata": {
        "id": "e21eb61b"
      },
      "outputs": [],
      "source": [
        "def train_val_dataset(train_path,path_dir):\n",
        "    \n",
        "    all_data = pd.read_csv(train_path)\n",
        "    \n",
        "    image_ids = all_data['0'].to_numpy()\n",
        "    labels = all_data['1'].to_numpy()\n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(image_ids, labels, test_size= 0.20, random_state = 122)\n",
        "    \n",
        "    train_dataset = TV_Dataset(X_train, y_train, path_dir)\n",
        "    val_dataset = TV_Dataset(X_val, y_val, path_dir)\n",
        "    \n",
        "    return train_dataset, val_dataset    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bfdf3b2f",
      "metadata": {
        "id": "bfdf3b2f"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if device =='cuda':\n",
        "  print(torch.cuda.memory_summary(device=device, abbreviated=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nZYE-r8DZ2j",
        "outputId": "71f0ff38-cfbb-47fc-dacc-620d4b888075"
      },
      "id": "5nZYE-r8DZ2j",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e15d5c07",
      "metadata": {
        "id": "e15d5c07"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.classes = 2\n",
        "        self.efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=False)\n",
        "        self.efficientnet.stem.conv = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        self.efficientnet.classifier.fc = nn.Linear(1280, self.classes, bias = True)\n",
        "        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        return self.efficientnet(x)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "64fe85ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64fe85ce",
        "outputId": "0dcc6dd3-cb47-49e8-c700-fd41c0ce06dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "122ea111",
      "metadata": {
        "id": "122ea111"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, optimizer, num_of_epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    \n",
        "    for _, epoch in tqdm(enumerate(range(num_of_epochs))):\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_of_epochs}')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        running_loss = 0.\n",
        "        running_accuracy = 0.\n",
        "        \n",
        "        \n",
        "        train_dataset, val_dataset = train_val_dataset(PATH + 'train_data.csv', PATH + 'small_train_data_set')\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset,batch_size=64)\n",
        "        val_loader = DataLoader(val_dataset,batch_size=32)\n",
        "        \n",
        "        print('-----------Trainning in Progress --------------')\n",
        "        for idx, data in tqdm(enumerate(train_loader),total = len(train_loader), position=0, leave=True):\n",
        "            images, labels = data\n",
        "            images = images.type(torch.float32).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = model(images)\n",
        "            labels = labels.type(torch.LongTensor).to(device)\n",
        "            \n",
        "            _ , preds = torch.max(outputs, 1)\n",
        "            \n",
        "            loss = criterion(outputs,labels)\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()*images.size(0)\n",
        "            running_accuracy += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss/len(train_dataset)\n",
        "        epoch_accuracy = running_accuracy/len(train_dataset)\n",
        "\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_acc.append(epoch_accuracy)\n",
        "        \n",
        "        print(f'Training Loss: {epoch_loss:.6f} Training Acc.: {epoch_accuracy:.6f}')\n",
        "        \n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0\n",
        "        running_accuracy = 0\n",
        "        \n",
        "        print('-----------Validation in Progress --------------')\n",
        "\n",
        "        for idx, data in tqdm(enumerate(val_loader),total = len(val_loader), position=0, leave=True):\n",
        "            images, labels = data\n",
        "            images = images.type(torch.float32).to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            labels = labels.type(torch.LongTensor).to(device)\n",
        "            \n",
        "            loss = criterion(outputs,labels)\n",
        "            \n",
        "            _ , preds = torch.max(outputs, 1)\n",
        "            \n",
        "            running_loss += loss.item()*images.size(0)\n",
        "            running_accuracy += torch.sum(preds == labels.data)\n",
        "        \n",
        "        val_loss = running_loss/len(val_dataset)\n",
        "        val_accuracy = running_accuracy/len(val_dataset)\n",
        "\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'\\nVal Loss: {val_loss:.4f} Val Acc.: {val_accuracy:.4f}\\n')\n",
        "    \n",
        "\n",
        "    return  model, train_acc, train_losses,  val_losses, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "e41c0098",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e41c0098",
        "outputId": "c0cd52b9-36c4-45fa-979d-31bd98b7d0b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [14:52<00:00, 42.50s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.550304 Training Acc.: 0.777778\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [03:36<00:00, 19.67s/it]\n",
            "1it [18:28, 1108.94s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5918 Val Acc.: 0.8031\n",
            "\n",
            "\n",
            "Epoch 2/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.493477 Training Acc.: 0.781636\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.20it/s]\n",
            "2it [18:58, 474.11s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5640 Val Acc.: 0.7938\n",
            "\n",
            "\n",
            "Epoch 3/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.17s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.466100 Training Acc.: 0.796296\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n",
            "3it [19:28, 271.14s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5329 Val Acc.: 0.7846\n",
            "\n",
            "\n",
            "Epoch 4/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.407673 Training Acc.: 0.817901\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n",
            "4it [19:58, 175.86s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5201 Val Acc.: 0.8308\n",
            "\n",
            "\n",
            "Epoch 5/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.275032 Training Acc.: 0.895062\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.21it/s]\n",
            "5it [20:28, 123.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5185 Val Acc.: 0.7908\n",
            "\n",
            "\n",
            "Epoch 6/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.224668 Training Acc.: 0.905864\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.25it/s]\n",
            "6it [20:57, 91.41s/it] "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5693 Val Acc.: 0.8123\n",
            "\n",
            "\n",
            "Epoch 7/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.163367 Training Acc.: 0.939043\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.24it/s]\n",
            "7it [21:27, 71.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.5375 Val Acc.: 0.2123\n",
            "\n",
            "\n",
            "Epoch 8/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.100289 Training Acc.: 0.959105\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.24it/s]\n",
            "8it [21:57, 58.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.7846 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 9/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.114735 Training Acc.: 0.959105\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n",
            "9it [22:26, 49.21s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5669 Val Acc.: 0.7938\n",
            "\n",
            "\n",
            "Epoch 10/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.080757 Training Acc.: 0.976852\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.21it/s]\n",
            "10it [22:56, 43.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5409 Val Acc.: 0.8185\n",
            "\n",
            "\n",
            "Epoch 11/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.038123 Training Acc.: 0.991512\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n",
            "11it [23:26, 39.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.4845 Val Acc.: 0.8185\n",
            "\n",
            "\n",
            "Epoch 12/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.022342 Training Acc.: 0.993827\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n",
            "12it [23:56, 36.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.6541 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 13/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.048058 Training Acc.: 0.982253\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n",
            "13it [24:26, 34.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.7006 Val Acc.: 0.7692\n",
            "\n",
            "\n",
            "Epoch 14/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.051842 Training Acc.: 0.983796\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n",
            "14it [24:56, 33.00s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.8148 Val Acc.: 0.8154\n",
            "\n",
            "\n",
            "Epoch 15/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.036684 Training Acc.: 0.986111\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n",
            "15it [25:26, 32.03s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.7170 Val Acc.: 0.7385\n",
            "\n",
            "\n",
            "Epoch 16/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.039297 Training Acc.: 0.982253\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n",
            "16it [25:56, 31.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.7039 Val Acc.: 0.7631\n",
            "\n",
            "\n",
            "Epoch 17/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.019103 Training Acc.: 0.993056\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n",
            "17it [26:25, 30.95s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5879 Val Acc.: 0.8308\n",
            "\n",
            "\n",
            "Epoch 18/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.017257 Training Acc.: 0.993827\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.20it/s]\n",
            "18it [26:55, 30.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.1772 Val Acc.: 0.7723\n",
            "\n",
            "\n",
            "Epoch 19/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.008907 Training Acc.: 0.997685\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.21it/s]\n",
            "19it [27:25, 30.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.0779 Val Acc.: 0.8185\n",
            "\n",
            "\n",
            "Epoch 20/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.018327 Training Acc.: 0.993056\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n",
            "20it [27:55, 83.79s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.9948 Val Acc.: 0.7938\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "trianed_model, train_acc, train_loss, val_loss, val_acc = train(model, criterion, optimizer, num_of_epochs = 20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_matrics(train_acc, train_loss, val_loss, val_acc):\n",
        "  \"\"\"plotting accuracies and losses in iteration\"\"\"\n",
        "\n",
        "  # creating data for x axes\n",
        "  epochs = len(train_acc)\n",
        "  epoch_ids = [epoch for epoch in epochs]\n",
        "\n",
        "  # dividing in sub-plots\n",
        "  plt.figure()\n",
        "  fig, axes = plt.subplots(1, 2, sharex=True, figsize=(10,5))\n",
        "\n",
        "  # plot 1\n",
        "  sns.lineplot(ax=axes[0], x=epoch_ids, y=train_acc, legend='Training Accuracy')\n",
        "  sns.lineplot(ax=axes[0], x=epoch_ids, y=val_acc, legend='Validation Accuracy')\n",
        "  axes[0].set_title('Model Accuracy')\n",
        "\n",
        "  # plot2 \n",
        "  sns.lineplot(ax=axes[1], x=epoch_ids, y=train_loss, legend='Training Loss')\n",
        "  sns.lineplot(ax=axes[1], x=epoch_ids, y=val_loss, legend='Validation Loss')\n",
        "  axes[0].set_title('Model Losses')\n",
        "\n",
        "  plt.show()\n",
        "  \n",
        "  return None"
      ],
      "metadata": {
        "id": "WAbhbsgeR8Ja"
      },
      "id": "WAbhbsgeR8Ja",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "6a1b0db9",
      "metadata": {
        "id": "6a1b0db9"
      },
      "outputs": [],
      "source": [
        "def test(model, criterion):\n",
        "  test_loader = DataLoader(Test_Dataset, batch_size=32)\n",
        "  model.eval()\n",
        "  running_loss = 0\n",
        "  running_accuracy = 0\n",
        "  print('-------Testing Model------------')\n",
        "  for idx, data in tqdm(enumerate(test_loader),total = len(test_loader), position=0, leave=True):\n",
        "    images, labels = data\n",
        "    images = images.to(device)\n",
        "    \n",
        "    outputs = model(images)\n",
        "    labels = labels.type(torch.LongTensor).to(device)\n",
        "    \n",
        "    loss = criterion(outputs,labels)\n",
        "    \n",
        "    _ , preds = torch.max(outputs, 1)\n",
        "    \n",
        "    running_loss += loss.item()*images.size(0)\n",
        "    running_accuracy += torch.sum(preds == labels.data)\n",
        "        \n",
        "  test_loss = running_loss/len(Test_Dataset)\n",
        "  test_accuracy = running_accuracy/len(Test_Dataset)\n",
        "\n",
        "\n",
        "  print(f'\\nTest Loss: {test_loss:.5f} Test Acc.: {test_accuracy:.5f}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(trianed_model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhlB47YMFMfG",
        "outputId": "1c972e19-e7ae-404e-c2a8-3ae0d73924c9"
      },
      "id": "nhlB47YMFMfG",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------Testing Model------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [04:31<00:00, 20.92s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Loss: 1.45743 Test Acc.: 0.75369\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fc4tOPrxk2ee"
      },
      "id": "fc4tOPrxk2ee",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}