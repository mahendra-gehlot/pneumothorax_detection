{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c085d928",
      "metadata": {
        "id": "c085d928"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ot48Em6A5jz",
        "outputId": "8538fe97-c6bf-43cc-9a29-e46d84b0d6c2"
      },
      "id": "9Ot48Em6A5jz",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# getting base path\n",
        "PATH = os.getcwd() + '/gdrive/MyDrive/AIMIA/'"
      ],
      "metadata": {
        "id": "GkbsYCtQBOsw"
      },
      "id": "GkbsYCtQBOsw",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install validators"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjumCrpXGzqc",
        "outputId": "f76b9ccb-8d5b-467b-dcfd-dc4ce4381f69"
      },
      "id": "FjumCrpXGzqc",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting validators\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators) (4.4.2)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=a304c001d74bfaa9fc93ee8a981198e7bcd15bc2bca01f6f600636b11d9bfddb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n",
            "Successfully built validators\n",
            "Installing collected packages: validators\n",
            "Successfully installed validators-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f55c10cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f55c10cf",
        "outputId": "3b4a4b46-f76c-4dd6-e08d-f6bc98c18ea8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  \"You are about to download and run code from an untrusted repository. In a future release, this won't \"\n",
            "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /root/.cache/torch/hub/torchhub.zip\n",
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:14: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  \"pytorch_quantization module not found, quantization will not be available\"\n",
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:18: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  \"pytorch_quantization module not found, quantization will not be available\"\n"
          ]
        }
      ],
      "source": [
        "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "39acacea",
      "metadata": {
        "id": "39acacea"
      },
      "outputs": [],
      "source": [
        "# train_data_m contain all the images name and ids\n",
        "all_data = pd.read_csv(PATH + 'train_data_m.csv')\n",
        "\n",
        "image_ids = all_data['file_name'].to_numpy()\n",
        "labels = all_data['target'].to_numpy()\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_ids, labels, test_size= 0.20, random_state=42)\n",
        "\n",
        "# creating dataset for train_validation\n",
        "train_df = pd.concat([pd.Series(X_train),pd.Series(y_train)],axis = 1)\n",
        "train_df.to_csv(PATH +'train_data.csv',index = False)\n",
        "\n",
        "# creating dataset for testing \n",
        "test_df = pd.concat([pd.Series(X_test),pd.Series(y_test)],axis = 1)\n",
        "test_df.to_csv(PATH + 'test_data.csv',index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7d02491e",
      "metadata": {
        "id": "7d02491e"
      },
      "outputs": [],
      "source": [
        "class PneumothoraxImgDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, annotations_file, img_dir, dim = 256):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform= transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((dim,dim)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "    \n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "1f23e11e",
      "metadata": {
        "id": "1f23e11e"
      },
      "outputs": [],
      "source": [
        "Test_Dataset = PneumothoraxImgDataset(PATH + 'test_data.csv', PATH + 'small_train_data_set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "df7f8f3c",
      "metadata": {
        "id": "df7f8f3c"
      },
      "outputs": [],
      "source": [
        "class TV_Dataset(Dataset):\n",
        "    def __init__(self, file_names, labels, img_dir,dim = 256):\n",
        "        self.img_name =file_names\n",
        "        self.labels = labels\n",
        "        self.img_dir = img_dir\n",
        "        self.transform= transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((dim,dim)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_name)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_name[idx])\n",
        "        image = read_image(img_path)\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "e21eb61b",
      "metadata": {
        "id": "e21eb61b"
      },
      "outputs": [],
      "source": [
        "def train_val_dataset(train_path,path_dir):\n",
        "    \n",
        "    all_data = pd.read_csv(train_path)\n",
        "    \n",
        "    image_ids = all_data['0'].to_numpy()\n",
        "    labels = all_data['1'].to_numpy()\n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(image_ids, labels, test_size= 0.20, random_state = 122)\n",
        "    \n",
        "    train_dataset = TV_Dataset(X_train, y_train, path_dir)\n",
        "    val_dataset = TV_Dataset(X_val, y_val, path_dir)\n",
        "    \n",
        "    return train_dataset, val_dataset    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "bfdf3b2f",
      "metadata": {
        "id": "bfdf3b2f"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if device =='cuda':\n",
        "  print(torch.cuda.memory_summary(device=device, abbreviated=False))"
      ],
      "metadata": {
        "id": "5nZYE-r8DZ2j"
      },
      "id": "5nZYE-r8DZ2j",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "e15d5c07",
      "metadata": {
        "id": "e15d5c07"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.classes = 2\n",
        "        self.efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=False)\n",
        "        self.efficientnet.stem.conv = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        self.efficientnet.classifier.fc = nn.Linear(1280, self.classes, bias = True)\n",
        "        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        return self.efficientnet(x)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "122ea111",
      "metadata": {
        "id": "122ea111"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, optimizer, num_of_epochs):\n",
        "    \n",
        "    train_losses = []\n",
        "    train_acc = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    \n",
        "    for _, epoch in tqdm(enumerate(range(num_of_epochs))):\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_of_epochs}')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        running_loss = 0.\n",
        "        running_accuracy = 0.\n",
        "        \n",
        "        \n",
        "        train_dataset, val_dataset = train_val_dataset(PATH + 'train_data.csv', PATH + 'small_train_data_set')\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset,batch_size=64)\n",
        "        val_loader = DataLoader(val_dataset,batch_size=32)\n",
        "        \n",
        "        print('-----------Trainning in Progress --------------')\n",
        "        for idx, data in tqdm(enumerate(train_loader),total = len(train_loader), position=0, leave=True):\n",
        "            images, labels = data\n",
        "            images = images.type(torch.float32).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = model(images)\n",
        "            labels = labels.type(torch.LongTensor).to(device)\n",
        "            \n",
        "            _ , preds = torch.max(outputs, 1)\n",
        "            \n",
        "            loss = criterion(outputs,labels)\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()*images.size(0)\n",
        "            running_accuracy += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss/len(train_dataset)\n",
        "        epoch_accuracy = running_accuracy/len(train_dataset)\n",
        "\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_acc.append(epoch_accuracy)\n",
        "        \n",
        "        print(f'Training Loss: {epoch_loss:.6f} Training Acc.: {epoch_accuracy:.6f}')\n",
        "        \n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0\n",
        "        running_accuracy = 0\n",
        "        \n",
        "        print('-----------Validation in Progress --------------')\n",
        "\n",
        "        for idx, data in tqdm(enumerate(val_loader),total = len(val_loader), position=0, leave=True):\n",
        "            images, labels = data\n",
        "            images = images.type(torch.float32).to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            labels = labels.type(torch.LongTensor).to(device)\n",
        "            \n",
        "            loss = criterion(outputs,labels)\n",
        "            \n",
        "            _ , preds = torch.max(outputs, 1)\n",
        "            \n",
        "            running_loss += loss.item()*images.size(0)\n",
        "            running_accuracy += torch.sum(preds == labels.data)\n",
        "        \n",
        "        val_loss = running_loss/len(val_dataset)\n",
        "        val_accuracy = running_accuracy/len(val_dataset)\n",
        "\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_accuracy)\n",
        "\n",
        "        print(f'\\nVal Loss: {val_loss:.4f} Val Acc.: {val_accuracy:.4f}\\n')\n",
        "\n",
        "    \n",
        "\n",
        "    return  model, train_acc, train_losses,  val_losses, val_accuracies"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_matrics(train_acc, train_loss, val_loss, val_acc):\n",
        "  \"\"\"plotting accuracies and losses in iteration\"\"\"\n",
        "\n",
        "  sns.set_theme()\n",
        "  \n",
        "  # creating data for x axes\n",
        "  epochs = len(train_acc)\n",
        "  epoch_ids = [epoch for epoch in range(1, epochs+1)]\n",
        "\n",
        "  # dividing in sub-plots\n",
        "  plt.figure()\n",
        "  fig, axes = plt.subplots(1, 2, sharex=True, figsize=(15,8))\n",
        "\n",
        "  # plot 1\n",
        "  sns.lineplot(ax=axes[0], x=epoch_ids, y=train_acc)\n",
        "  sns.lineplot(ax=axes[0], x=epoch_ids, y=val_acc)\n",
        "  axes[0].set_title('Model Accuracy')\n",
        "  axes[0].legend(['Train Acc', 'Val Acc'])\n",
        "\n",
        "  # plot2 \n",
        "  sns.lineplot(ax=axes[1], x=epoch_ids, y=train_loss)\n",
        "  sns.lineplot(ax=axes[1], x=epoch_ids, y=val_loss)\n",
        "  axes[1].set_title('Model Losses')\n",
        "  axes[1].legend(['Train Loss', 'Val Loss'])\n",
        "\n",
        "  plt.show()\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "WAbhbsgeR8Ja"
      },
      "id": "WAbhbsgeR8Ja",
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "6a1b0db9",
      "metadata": {
        "id": "6a1b0db9"
      },
      "outputs": [],
      "source": [
        "def test(model, criterion):\n",
        "\n",
        "  test_loader = DataLoader(Test_Dataset, batch_size=32)\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  running_loss = 0\n",
        "  running_accuracy = 0\n",
        "\n",
        "  print('-------Testing Model------------')\n",
        "  for idx, data in tqdm(enumerate(test_loader),total = len(test_loader), position=0, leave=True):\n",
        "    \n",
        "    images, labels = data\n",
        "    images = images.to(device)\n",
        "    \n",
        "    outputs = model(images)\n",
        "    labels = labels.type(torch.LongTensor).to(device)\n",
        "    \n",
        "    loss = criterion(outputs,labels)\n",
        "    \n",
        "    _ , preds = torch.max(outputs, 1)\n",
        "    \n",
        "    running_loss += loss.item()*images.size(0)\n",
        "    running_accuracy += torch.sum(preds == labels.data)\n",
        "        \n",
        "  test_loss = running_loss/len(Test_Dataset)\n",
        "  test_accuracy = running_accuracy/len(Test_Dataset)\n",
        "\n",
        "\n",
        "  print(f'\\nTest Loss: {test_loss:.5f} Test Acc.: {test_accuracy:.5f}\\n')\n",
        "\n",
        "  return test_loss, test_accuracy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "# setting up logger\n",
        "logger = logging.getLogger('Model')\n",
        "logger.setLevel(logging.INFO)\n",
        "fh = logging.FileHandler(PATH + 'model_logs.log', mode = \"a\")\n",
        "fh.setLevel(logging.INFO)\n",
        "logger.addHandler(fh)\n",
        "# console output off\n",
        "logger.propagate = False"
      ],
      "metadata": {
        "id": "MqMtf-sptaNr"
      },
      "id": "MqMtf-sptaNr",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def execute(version, model, criterion, optimizer, epochs, plotting = True, perform_testing = True):\n",
        "\n",
        "  logger.info(f'Version: {version}\\n')\n",
        "  trianed_model, train_acc, train_loss, val_loss, val_acc = train(model, criterion, optimizer, num_of_epochs = epochs)\n",
        "\n",
        "  logger.info('Epoch   Training Accuracy  Validation Accuracy')\n",
        "  for idx in range(len(train_acc)):\n",
        "    logger.info(f'{idx+1}      {train_acc[idx]:.5f}              {val_acc[idx]:.5f}')\n",
        "\n",
        "  if plotting:\n",
        "    print(type(train_acc[0]))\n",
        "    plot_matrics(train_acc, train_loss, val_loss, val_acc)\n",
        "    \n",
        "\n",
        "  if perform_testing:\n",
        "    test_loss, test_acc = test(trianed_model, criterion)\n",
        "    logger.info(f'Testing Accuracy {test_acc:.5f}')\n",
        "\n",
        "  return None"
      ],
      "metadata": {
        "id": "nhlB47YMFMfG"
      },
      "id": "nhlB47YMFMfG",
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model defination\n",
        "model = NeuralNetwork().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# args to model\n",
        "args = dict()\n",
        "args['version'] = 'v0'\n",
        "args['model'] = model\n",
        "args['criterion'] = criterion\n",
        "args['optimizer'] = optimizer\n",
        "args['epochs'] = 20\n",
        "args['plotting'] = False\n",
        "args['perform_testing'] = True"
      ],
      "metadata": {
        "id": "fc4tOPrxk2ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f0917de-3f82-434a-e8bf-91250ca22bfd"
      },
      "id": "fc4tOPrxk2ee",
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "execute(**args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB86Pt4igQMn",
        "outputId": "574f162e-244b-4251-e3da-9111c9b43fed"
      },
      "id": "JB86Pt4igQMn",
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.569929 Training Acc.: 0.765432\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n",
            "1it [00:30, 30.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.6086 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 2/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.504546 Training Acc.: 0.790123\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n",
            "2it [01:00, 30.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5088 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 3/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.390254 Training Acc.: 0.837191\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.18it/s]\n",
            "3it [01:31, 30.71s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5103 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 4/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.211828 Training Acc.: 0.922840\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.18it/s]\n",
            "4it [02:02, 30.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5260 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 5/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.18s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.178580 Training Acc.: 0.929784\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.21it/s]\n",
            "5it [02:31, 30.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5847 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 6/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.107866 Training Acc.: 0.962963\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.13it/s]\n",
            "6it [03:02, 30.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.2257 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 7/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:29<00:00,  1.41s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.050166 Training Acc.: 0.985340\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:06<00:00,  1.73it/s]\n",
            "7it [03:38, 32.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.9267 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 8/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.040640 Training Acc.: 0.985340\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.17it/s]\n",
            "8it [04:08, 31.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.3308 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 9/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.056316 Training Acc.: 0.982253\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.15it/s]\n",
            "9it [04:38, 31.09s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.7017 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 10/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.045911 Training Acc.: 0.983796\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.20it/s]\n",
            "10it [05:08, 30.75s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.0771 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 11/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:26<00:00,  1.24s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.029923 Training Acc.: 0.985340\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.17it/s]\n",
            "11it [05:39, 30.87s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.3844 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 12/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.015249 Training Acc.: 0.996914\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.17it/s]\n",
            "12it [06:10, 30.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.3540 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 13/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:27<00:00,  1.31s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.007540 Training Acc.: 0.996914\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.18it/s]\n",
            "13it [06:43, 31.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.4047 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 14/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.002299 Training Acc.: 1.000000\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n",
            "14it [07:13, 31.02s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.3859 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 15/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.001513 Training Acc.: 0.999228\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.17it/s]\n",
            "15it [07:43, 30.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.4428 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 16/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.000739 Training Acc.: 1.000000\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.14it/s]\n",
            "16it [08:13, 30.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.6272 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 17/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.000276 Training Acc.: 1.000000\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.18it/s]\n",
            "17it [08:44, 30.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.5558 Val Acc.: 0.8000\n",
            "\n",
            "\n",
            "Epoch 18/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:24<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.000192 Training Acc.: 1.000000\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.23it/s]\n",
            "18it [09:13, 30.34s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.5521 Val Acc.: 0.7969\n",
            "\n",
            "\n",
            "Epoch 19/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.000143 Training Acc.: 1.000000\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.22it/s]\n",
            "19it [09:43, 30.24s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.5631 Val Acc.: 0.7969\n",
            "\n",
            "\n",
            "Epoch 20/20\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.19s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.000121 Training Acc.: 1.000000\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.20it/s]\n",
            "20it [10:14, 30.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 1.5744 Val Acc.: 0.7938\n",
            "\n",
            "-------Testing Model------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [04:09<00:00, 19.23s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Loss: 1.84269 Test Acc.: 0.76847\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}