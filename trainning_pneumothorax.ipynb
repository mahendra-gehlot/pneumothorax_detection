{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ff045a70",
      "metadata": {
        "id": "ff045a70"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "c085d928",
      "metadata": {
        "id": "c085d928"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torchvision.io import read_image\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm\n",
        "import copy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ot48Em6A5jz",
        "outputId": "1cd8b6bd-b0f5-44fc-ceae-8648062332d5"
      },
      "id": "9Ot48Em6A5jz",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PATH = os.getcwd() + '/gdrive/MyDrive/AIMIA/'"
      ],
      "metadata": {
        "id": "GkbsYCtQBOsw"
      },
      "id": "GkbsYCtQBOsw",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install validators"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FjumCrpXGzqc",
        "outputId": "80274610-5369-4e6d-a2cb-d0a966b856ae"
      },
      "id": "FjumCrpXGzqc",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting validators\n",
            "  Downloading validators-0.20.0.tar.gz (30 kB)\n",
            "Requirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from validators) (4.4.2)\n",
            "Building wheels for collected packages: validators\n",
            "  Building wheel for validators (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for validators: filename=validators-0.20.0-py3-none-any.whl size=19582 sha256=15a9f8236282d998188476a3e3bde08647db7306493d91cc417f564f51fa6721\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/55/ab/36a76989f7f88d9ca7b1f68da6d94252bb6a8d6ad4f18e04e9\n",
            "Successfully built validators\n",
            "Installing collected packages: validators\n",
            "Successfully installed validators-0.20.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "f55c10cf",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f55c10cf",
        "outputId": "0ec1a7b0-ae79-43d2-ad9e-422a74075442"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/hub.py:267: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  \"You are about to download and run code from an untrusted repository. In a future release, this won't \"\n",
            "Downloading: \"https://github.com/NVIDIA/DeepLearningExamples/zipball/torchhub\" to /root/.cache/torch/hub/torchhub.zip\n",
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/common.py:14: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  \"pytorch_quantization module not found, quantization will not be available\"\n",
            "/root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub/PyTorch/Classification/ConvNets/image_classification/models/efficientnet.py:18: UserWarning: pytorch_quantization module not found, quantization will not be available\n",
            "  \"pytorch_quantization module not found, quantization will not be available\"\n"
          ]
        }
      ],
      "source": [
        "utils = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_convnets_processing_utils')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "39acacea",
      "metadata": {
        "id": "39acacea"
      },
      "outputs": [],
      "source": [
        "all_data = pd.read_csv(PATH + 'train_data_m.csv')\n",
        "\n",
        "image_ids = all_data['file_name'].to_numpy()\n",
        "labels = all_data['target'].to_numpy()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(image_ids, labels, test_size= 0.20, random_state=42)\n",
        "\n",
        "\n",
        "train_df = pd.concat([pd.Series(X_train),pd.Series(y_train)],axis = 1)\n",
        "\n",
        "train_df.to_csv(PATH +'train_data.csv',index = False)\n",
        "\n",
        "test_df = pd.concat([pd.Series(X_test),pd.Series(y_test)],axis = 1)\n",
        "\n",
        "test_df.to_csv(PATH + 'test_data.csv',index = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "7d02491e",
      "metadata": {
        "id": "7d02491e"
      },
      "outputs": [],
      "source": [
        "class PneumothoraxImgDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir,dim = 256):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform= transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((dim,dim)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "1f23e11e",
      "metadata": {
        "id": "1f23e11e"
      },
      "outputs": [],
      "source": [
        "Test_Dataset = PneumothoraxImgDataset(PATH + 'test_data.csv',PATH + 'small_train_data_set')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "df7f8f3c",
      "metadata": {
        "id": "df7f8f3c"
      },
      "outputs": [],
      "source": [
        "class TV_Dataset(Dataset):\n",
        "    def __init__(self, file_names, labels, img_dir,dim = 256):\n",
        "        self.img_name = file_names\n",
        "        self.labels = labels\n",
        "        self.img_dir = img_dir\n",
        "        self.transform= transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Resize((dim,dim)),\n",
        "            transforms.ToTensor()\n",
        "        ])\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_name)\n",
        "    \n",
        "    def __getitem__(self,idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_name[idx])\n",
        "        image = read_image(img_path)\n",
        "        label = self.labels[idx]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        \n",
        "        return image, label "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "e21eb61b",
      "metadata": {
        "id": "e21eb61b"
      },
      "outputs": [],
      "source": [
        "def train_val_dataset(train_path,path_dir):\n",
        "    \n",
        "    all_data = pd.read_csv(train_path)\n",
        "    \n",
        "    image_ids = all_data['0'].to_numpy()\n",
        "    labels = all_data['1'].to_numpy()\n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(image_ids, labels, test_size= 0.20)\n",
        "    \n",
        "    train_dataset = TV_Dataset(X_train, y_train, path_dir)\n",
        "    val_dataset = TV_Dataset(X_val, y_val, path_dir)\n",
        "    \n",
        "    return train_dataset, val_dataset    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "bfdf3b2f",
      "metadata": {
        "id": "bfdf3b2f"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if device =='cuda':\n",
        "  print(torch.cuda.memory_summary(device=device, abbreviated=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5nZYE-r8DZ2j",
        "outputId": "f4afb7a8-d8fa-43dd-c92c-3e3e6460f3e4"
      },
      "id": "5nZYE-r8DZ2j",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|===========================================================================|\n",
            "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
            "|---------------------------------------------------------------------------|\n",
            "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
            "|===========================================================================|\n",
            "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Allocations           |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Active allocs         |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
            "|       from large pool |       0    |       0    |       0    |       0    |\n",
            "|       from small pool |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
            "|---------------------------------------------------------------------------|\n",
            "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
            "|===========================================================================|\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "e15d5c07",
      "metadata": {
        "id": "e15d5c07"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "        self.classes = 2\n",
        "        self.efficientnet = torch.hub.load('NVIDIA/DeepLearningExamples:torchhub', 'nvidia_efficientnet_b0', pretrained=False)\n",
        "        self.efficientnet.stem.conv = nn.Conv2d(1, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
        "        self.efficientnet.classifier.fc = nn.Linear(1280, self.classes, bias = True)\n",
        "        \n",
        "    \n",
        "    def forward(self,x):\n",
        "        return self.efficientnet(x)\n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "64fe85ce",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64fe85ce",
        "outputId": "484bdf47-8287-4fd6-aa14-ce1923713eaa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/NVIDIA_DeepLearningExamples_torchhub\n"
          ]
        }
      ],
      "source": [
        "model = NeuralNetwork().to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "122ea111",
      "metadata": {
        "id": "122ea111"
      },
      "outputs": [],
      "source": [
        "def train(model, criterion, optimizer, num_of_epochs):\n",
        "    \n",
        "#     best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    \n",
        "    best_acc = 0.0\n",
        "    \n",
        "    for _, epoch in tqdm(enumerate(range(num_of_epochs))):\n",
        "        print(f'\\nEpoch {epoch + 1}/{num_of_epochs}')\n",
        "        \n",
        "        model.train()\n",
        "        \n",
        "        running_loss = 0.\n",
        "        running_accuracy = 0.\n",
        "        \n",
        "        \n",
        "        train_dataset, val_dataset = train_val_dataset(PATH + 'train_data.csv', PATH + 'small_train_data_set')\n",
        "        \n",
        "        train_loader = DataLoader(train_dataset,batch_size=64)\n",
        "        val_loader = DataLoader(val_dataset,batch_size=32)\n",
        "        \n",
        "        print('-----------Trainning in Progress --------------')\n",
        "        for idx, data in tqdm(enumerate(train_loader),total = len(train_loader), position=0, leave=True):\n",
        "            images, labels = data\n",
        "            images = images.type(torch.float32).to(device)\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            outputs = model(images)\n",
        "            labels = labels.type(torch.LongTensor).to(device)\n",
        "            \n",
        "            _ , preds = torch.max(outputs, 1)\n",
        "            \n",
        "            loss = criterion(outputs,labels)\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "            running_loss += loss.item()*images.size(0)\n",
        "            running_accuracy += torch.sum(preds == labels.data)\n",
        "\n",
        "        epoch_loss = running_loss/len(train_dataset)\n",
        "        epoch_accuracy = running_accuracy/len(train_dataset)\n",
        "        \n",
        "        print(f'Training Loss: {epoch_loss:.6f} Training Acc.: {epoch_accuracy:.6f}')\n",
        "        \n",
        "        model.eval()\n",
        "\n",
        "        running_loss = 0\n",
        "        running_accuracy = 0\n",
        "        \n",
        "        print('-----------Validation in Progress --------------')\n",
        "\n",
        "        for idx, data in tqdm(enumerate(val_loader),total = len(val_loader), position=0, leave=True):\n",
        "            images, labels = data\n",
        "            images = images.type(torch.float32).to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            labels = labels.type(torch.LongTensor).to(device)\n",
        "            \n",
        "            loss = criterion(outputs,labels)\n",
        "            \n",
        "            _ , preds = torch.max(outputs, 1)\n",
        "            \n",
        "            running_loss += loss.item()*images.size(0)\n",
        "            running_accuracy += torch.sum(preds == labels.data)\n",
        "        \n",
        "        val_loss = running_loss/len(val_dataset)\n",
        "        val_accuracy = running_accuracy/len(val_dataset)\n",
        "        print(f'\\nVal Loss: {val_loss:.4f} Val Acc.: {val_accuracy:.4f}\\n')\n",
        "    \n",
        "\n",
        "    return  model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "e41c0098",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e41c0098",
        "outputId": "70fb9189-f478-4a19-866c-cffde638aed8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r0it [00:00, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.429615 Training Acc.: 0.819444\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.18it/s]\n",
            "1it [00:30, 30.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5133 Val Acc.: 0.7908\n",
            "\n",
            "\n",
            "Epoch 2/3\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:25<00:00,  1.20s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.351661 Training Acc.: 0.846451\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:04<00:00,  2.21it/s]\n",
            "2it [01:00, 30.19s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.4965 Val Acc.: 0.8031\n",
            "\n",
            "\n",
            "Epoch 3/3\n",
            "-----------Trainning in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21/21 [00:26<00:00,  1.25s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Loss: 0.194139 Training Acc.: 0.929012\n",
            "-----------Validation in Progress --------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 11/11 [00:05<00:00,  2.19it/s]\n",
            "3it [01:31, 30.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Val Loss: 0.5334 Val Acc.: 0.8062\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "trianed_model = train(model, criterion, optimizer, num_of_epochs=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "6a1b0db9",
      "metadata": {
        "id": "6a1b0db9"
      },
      "outputs": [],
      "source": [
        "def test(model, criterion):\n",
        "  test_loader = DataLoader(Test_Dataset, batch_size=32)\n",
        "  model.eval()\n",
        "  running_loss = 0\n",
        "  running_accuracy = 0\n",
        "  print('-------Testing Model------------')\n",
        "  for idx, data in tqdm(enumerate(test_loader),total = len(test_loader), position=0, leave=True):\n",
        "    images, labels = data\n",
        "    images = images.to(device)\n",
        "    \n",
        "    outputs = model(images)\n",
        "    labels = labels.type(torch.LongTensor).to(device)\n",
        "    \n",
        "    loss = criterion(outputs,labels)\n",
        "    \n",
        "    _ , preds = torch.max(outputs, 1)\n",
        "    \n",
        "    running_loss += loss.item()*images.size(0)\n",
        "    running_accuracy += torch.sum(preds == labels.data)\n",
        "        \n",
        "  test_loss = running_loss/len(Test_Dataset)\n",
        "  test_accuracy = running_accuracy/len(Test_Dataset)\n",
        "\n",
        "\n",
        "  print(f'\\nTest Loss: {test_loss:.5f} Test Acc.: {test_accuracy:.5f}\\n')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test(trianed_model, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhlB47YMFMfG",
        "outputId": "fcb43dd9-a5c5-4660-aceb-16d5d4c1b0d1"
      },
      "id": "nhlB47YMFMfG",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------Testing Model------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 13/13 [00:06<00:00,  2.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Test Loss: 0.61701 Test Acc.: 0.76847\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fc4tOPrxk2ee"
      },
      "id": "fc4tOPrxk2ee",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}